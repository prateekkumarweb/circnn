{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['AlexNet', 'alexnet']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([4096, 9216])\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    i = 0\n",
    "    with open(\"foo.txt\", \"w\") as f:\n",
    "        f.write(str(param.shape[0])+\" \"+str(param.shape[1])+\"\\n\")\n",
    "        for row in param:\n",
    "            for val in row:\n",
    "                f.write(str(float(val.data))+\" \")\n",
    "            f.write(\"\\n\")\n",
    "            if i%100 == 0:\n",
    "                print(i)\n",
    "            i = i+1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate mat.csv from bcm.cpp file as follows:**\n",
    "```sh\n",
    "$ g++ -O3 bcm.cpp\n",
    "$ ./a.out foo.txt mat.csv 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37748736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.genfromtxt('mat.csv', delimiter=' ')\n",
    "print(matrix.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(os.path.abspath('ILSVRC2012_img_val'), transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=10, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "          .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 56.522 Prec@5 79.066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(56.5220)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 38.210 Prec@5 64.340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(38.2100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.genfromtxt('mat.csv', delimiter=' ')\n",
    "print(matrix.size)\n",
    "\n",
    "matrix = torch.Tensor(matrix)\n",
    "model.state_dict()['classifier.1.weight'].data.copy_(matrix)\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37748736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/prateek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/5000]\tTime 1.325 (1.325)\tLoss 2.8399 (2.8399)\tPrec@1 70.000 (70.000)\tPrec@5 90.000 (90.000)\n",
      "Test: [100/5000]\tTime 0.504 (0.495)\tLoss 2.8699 (2.5159)\tPrec@1 70.000 (70.990)\tPrec@5 90.000 (87.822)\n",
      "Test: [200/5000]\tTime 0.446 (0.657)\tLoss 3.0745 (2.8579)\tPrec@1 30.000 (64.677)\tPrec@5 90.000 (84.577)\n",
      "Test: [300/5000]\tTime 0.470 (0.601)\tLoss 4.2991 (3.1244)\tPrec@1 20.000 (59.568)\tPrec@5 60.000 (81.661)\n",
      "Test: [400/5000]\tTime 0.480 (0.572)\tLoss 1.8177 (3.1867)\tPrec@1 100.000 (57.506)\tPrec@5 100.000 (80.748)\n",
      "Test: [500/5000]\tTime 0.481 (0.555)\tLoss 1.4061 (3.0267)\tPrec@1 90.000 (60.898)\tPrec@5 100.000 (82.655)\n",
      "Test: [600/5000]\tTime 0.484 (0.543)\tLoss 3.4103 (3.0781)\tPrec@1 70.000 (60.932)\tPrec@5 70.000 (82.413)\n",
      "Test: [700/5000]\tTime 0.489 (0.544)\tLoss 2.3944 (3.0504)\tPrec@1 80.000 (61.583)\tPrec@5 90.000 (82.810)\n",
      "Test: [800/5000]\tTime 0.492 (0.535)\tLoss 3.2778 (3.0404)\tPrec@1 60.000 (61.923)\tPrec@5 80.000 (83.171)\n",
      "Test: [900/5000]\tTime 0.474 (0.530)\tLoss 3.4836 (3.0881)\tPrec@1 40.000 (60.599)\tPrec@5 90.000 (82.630)\n",
      "Test: [1000/5000]\tTime 0.441 (0.524)\tLoss 3.1494 (3.1100)\tPrec@1 30.000 (59.760)\tPrec@5 80.000 (82.498)\n",
      "Test: [1100/5000]\tTime 0.465 (0.521)\tLoss 3.0371 (3.1254)\tPrec@1 50.000 (59.519)\tPrec@5 70.000 (82.552)\n",
      "Test: [1200/5000]\tTime 0.476 (0.519)\tLoss 3.0347 (3.1364)\tPrec@1 30.000 (58.993)\tPrec@5 90.000 (82.556)\n",
      "Test: [1300/5000]\tTime 0.483 (0.516)\tLoss 2.6794 (3.1367)\tPrec@1 80.000 (58.939)\tPrec@5 90.000 (82.952)\n",
      "Test: [1400/5000]\tTime 0.397 (0.514)\tLoss 2.8811 (3.1457)\tPrec@1 90.000 (58.680)\tPrec@5 90.000 (82.962)\n",
      "Test: [1500/5000]\tTime 0.525 (0.512)\tLoss 2.1840 (3.1458)\tPrec@1 90.000 (58.921)\tPrec@5 90.000 (83.178)\n",
      "Test: [1600/5000]\tTime 0.480 (0.511)\tLoss 2.3485 (3.1499)\tPrec@1 90.000 (58.588)\tPrec@5 90.000 (83.142)\n",
      "Test: [1700/5000]\tTime 0.545 (0.520)\tLoss 2.0649 (3.1210)\tPrec@1 100.000 (59.424)\tPrec@5 100.000 (83.504)\n",
      "Test: [1800/5000]\tTime 0.400 (0.519)\tLoss 3.4972 (3.1276)\tPrec@1 50.000 (59.167)\tPrec@5 90.000 (83.520)\n",
      "Test: [1900/5000]\tTime 0.486 (0.522)\tLoss 2.8338 (3.1316)\tPrec@1 80.000 (59.269)\tPrec@5 90.000 (83.425)\n",
      "Test: [2000/5000]\tTime 0.749 (0.521)\tLoss 4.1874 (3.1331)\tPrec@1 50.000 (59.155)\tPrec@5 90.000 (83.408)\n",
      "Test: [2100/5000]\tTime 0.470 (0.519)\tLoss 4.6905 (3.1722)\tPrec@1 30.000 (58.624)\tPrec@5 60.000 (82.889)\n",
      "Test: [2200/5000]\tTime 0.468 (0.517)\tLoss 4.2519 (3.2132)\tPrec@1 20.000 (57.996)\tPrec@5 50.000 (82.322)\n",
      "Test: [2300/5000]\tTime 0.448 (0.515)\tLoss 4.3296 (3.2549)\tPrec@1 50.000 (57.388)\tPrec@5 60.000 (81.786)\n",
      "Test: [2400/5000]\tTime 0.621 (0.514)\tLoss 3.9138 (3.2920)\tPrec@1 60.000 (56.935)\tPrec@5 80.000 (81.270)\n",
      "Test: [2500/5000]\tTime 0.509 (0.517)\tLoss 1.9904 (3.3279)\tPrec@1 90.000 (56.265)\tPrec@5 100.000 (80.712)\n",
      "Test: [2600/5000]\tTime 0.478 (0.517)\tLoss 4.2004 (3.3644)\tPrec@1 50.000 (55.590)\tPrec@5 100.000 (80.161)\n",
      "Test: [2700/5000]\tTime 0.555 (0.517)\tLoss 3.0008 (3.3903)\tPrec@1 90.000 (55.302)\tPrec@5 90.000 (79.815)\n",
      "Test: [2800/5000]\tTime 0.476 (0.517)\tLoss 3.3570 (3.4123)\tPrec@1 80.000 (55.005)\tPrec@5 100.000 (79.500)\n",
      "Test: [2900/5000]\tTime 0.586 (0.516)\tLoss 3.3765 (3.4245)\tPrec@1 80.000 (55.095)\tPrec@5 90.000 (79.462)\n",
      "Test: [3000/5000]\tTime 0.593 (0.516)\tLoss 4.7794 (3.4553)\tPrec@1 10.000 (54.565)\tPrec@5 40.000 (78.947)\n",
      "Test: [3100/5000]\tTime 0.443 (0.520)\tLoss 4.5193 (3.4781)\tPrec@1 30.000 (54.373)\tPrec@5 70.000 (78.646)\n",
      "Test: [3200/5000]\tTime 0.523 (0.518)\tLoss 2.1848 (3.4990)\tPrec@1 90.000 (53.989)\tPrec@5 100.000 (78.285)\n",
      "Test: [3300/5000]\tTime 0.463 (0.518)\tLoss 4.6107 (3.5184)\tPrec@1 50.000 (53.717)\tPrec@5 60.000 (77.934)\n",
      "Test: [3400/5000]\tTime 0.391 (0.518)\tLoss 4.6081 (3.5367)\tPrec@1 40.000 (53.446)\tPrec@5 70.000 (77.698)\n",
      "Test: [3500/5000]\tTime 0.440 (0.517)\tLoss 5.1420 (3.5478)\tPrec@1 10.000 (53.353)\tPrec@5 20.000 (77.538)\n",
      "Test: [3600/5000]\tTime 0.728 (0.517)\tLoss 3.9853 (3.5617)\tPrec@1 50.000 (53.177)\tPrec@5 70.000 (77.342)\n",
      "Test: [3700/5000]\tTime 0.481 (0.517)\tLoss 5.1120 (3.5762)\tPrec@1 10.000 (53.061)\tPrec@5 30.000 (77.120)\n",
      "Test: [3800/5000]\tTime 0.437 (0.516)\tLoss 4.4104 (3.5940)\tPrec@1 60.000 (52.794)\tPrec@5 80.000 (76.848)\n",
      "Test: [3900/5000]\tTime 0.414 (0.515)\tLoss 2.6052 (3.6116)\tPrec@1 70.000 (52.494)\tPrec@5 100.000 (76.524)\n",
      "Test: [4000/5000]\tTime 0.505 (0.514)\tLoss 3.6850 (3.6302)\tPrec@1 60.000 (52.167)\tPrec@5 90.000 (76.186)\n",
      "Test: [4100/5000]\tTime 0.499 (0.513)\tLoss 3.5716 (3.6390)\tPrec@1 60.000 (52.009)\tPrec@5 90.000 (76.062)\n",
      "Test: [4200/5000]\tTime 0.476 (0.513)\tLoss 3.8082 (3.6535)\tPrec@1 60.000 (51.738)\tPrec@5 70.000 (75.801)\n",
      "Test: [4300/5000]\tTime 0.549 (0.512)\tLoss 4.7504 (3.6671)\tPrec@1 10.000 (51.523)\tPrec@5 60.000 (75.636)\n",
      "Test: [4400/5000]\tTime 0.500 (0.512)\tLoss 3.9479 (3.6743)\tPrec@1 70.000 (51.397)\tPrec@5 80.000 (75.587)\n",
      "Test: [4500/5000]\tTime 0.447 (0.511)\tLoss 1.6237 (3.6849)\tPrec@1 90.000 (51.220)\tPrec@5 100.000 (75.401)\n",
      "Test: [4600/5000]\tTime 0.469 (0.511)\tLoss 3.9495 (3.6923)\tPrec@1 50.000 (51.185)\tPrec@5 50.000 (75.312)\n",
      "Test: [4700/5000]\tTime 0.427 (0.510)\tLoss 3.3239 (3.6909)\tPrec@1 50.000 (51.240)\tPrec@5 90.000 (75.382)\n",
      "Test: [4800/5000]\tTime 0.438 (0.509)\tLoss 3.6325 (3.6803)\tPrec@1 70.000 (51.498)\tPrec@5 100.000 (75.586)\n",
      "Test: [4900/5000]\tTime 0.443 (0.509)\tLoss 2.7884 (3.6851)\tPrec@1 70.000 (51.377)\tPrec@5 90.000 (75.554)\n",
      " * Prec@1 51.710 Prec@5 75.750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(51.7100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.genfromtxt('mat.csv', delimiter=' ')\n",
    "print(matrix.size)\n",
    "\n",
    "matrix = torch.Tensor(matrix)\n",
    "model.state_dict()['classifier.1.weight'].data.copy_(matrix)\n",
    "validate(val_loader, model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
